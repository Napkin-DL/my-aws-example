{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike-Share Demand Forecasting 2a: Modelling with [Amazon Forecast](https://aws.amazon.com/forecast/)\n",
    "\n",
    "We'll look at 3 ways to tackle the bike-share demand forecasting problem set up previously in the data preparation notebook:\n",
    "\n",
    "1. Applying an AWS \"Managed AI\" service ([Amazon Forecast](https://aws.amazon.com/forecast/)), to tackle the scenario as a common/commodity business problem\n",
    "2. Using a SageMaker built-in algorithm ([DeepAR](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html)), to approach it as a common/commodity algorithm in our own data science workbench\n",
    "3. Using a custom SageMaker algorithm, to take on the core modelling as a value-added differentiator working in our data science workbench.\n",
    "\n",
    "These approaches represent different cost/control trade-offs that we might make as a business.\n",
    "\n",
    "**This notebook shows how to apply the Amazon Forecast service *via the AWS console*, although the same actions can all be performed via API instead.**\n",
    "\n",
    "<img src=\"BlogImages/amazon_forecast.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and configuration\n",
    "\n",
    "As usual we start by loading libraries, defining configuration, and connecting to AWS SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data configuration is initialised and stored in the Data Preparation notebook\n",
    "# ...We just retrieve it here:\n",
    "%store -r\n",
    "assert bucket, \"Variable `bucket` missing from IPython store\"\n",
    "\n",
    "assert data_prefix, \"Variable `data_prefix` missing from IPython store\"\n",
    "assert target_train_filename, \"Variable `target_train_filename` missing from IPython store\"\n",
    "assert target_test_filename, \"Variable `target_test_filename` missing from IPython store\"\n",
    "assert related_filename, \"Variable `related_filename` missing from IPython store\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Built-Ins:\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from IPython.core.display import display, HTML\n",
    "import pandas as pd\n",
    "\n",
    "# Local Dependencies:\n",
    "%aimport util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we connect to our AWS SDKs, and initialise our access role (which may wait a little while to ensure any newly created permissions propagate):\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    If you haven't already, you'll need to grant this notebook access to Amazon Forecast.\n",
    "    The simplest way to do this is to click on the \"IAM Role ARN\" hyperlink in the details page for this Notebook Instance on the SageMaker Console.<br/>\n",
    "    You can \"Attach Policies\" and add \"AmazonForecastFullAccess\", as visible below:\n",
    "    <img src=\"BlogImages/ForecastAccessPermissions.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session() \n",
    "region = session.region_name\n",
    "forecast = session.client(service_name=\"forecast\") \n",
    "forecast_query = session.client(service_name=\"forecastquery\")\n",
    "s3 = session.client(service_name=\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The overall workflow of Amazon Forecast is a typical batch ML model training approach, as summarized below.\n",
    "\n",
    "Although the `forecast` SDK initialised above supports doing all these steps programmatically, **we'll be using the AWS Console approach** to show you around.\n",
    "\n",
    "<img src=\"BlogImages/outline.png\">\n",
    "\n",
    "<img src=\"BlogImages/forecast_workflow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Selecting the Amazon Forecast domain<a class=\"anchor\" id=\"prepare\"/>\n",
    "\n",
    "Amazon Forecast defines a set of **domains** (documented [here](https://docs.aws.amazon.com/forecast/latest/dg/howitworks-domains-ds-types.html)), for common forecasting use cases.\n",
    "\n",
    "The domain provides a **base data schema** and featurizations/model architectures tailored towards that particular use case. We can add custom data fields as well (and we will)... but in general the more advantage we can take of the structure in the out-of-the-box domain model, the better model performance we'll see.\n",
    "\n",
    "<img src=\"BlogImages/AmazonForecastDomains.png\"/>\n",
    "\n",
    "In this example we'll use the [`RETAIL`](https://docs.aws.amazon.com/forecast/latest/dg/retail-domain.html) domain, but it could also be argued that [`METRICS`](https://docs.aws.amazon.com/forecast/latest/dg/metrics-domain.html) or even some others might be just as good a fit! If you have time, feel free to experiment with other domains and see if performance can be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preparing the data\n",
    "\n",
    "The [domain documentation](https://docs.aws.amazon.com/forecast/latest/dg/retail-domain.html) tells us what mandatory fields we need to provide, so we'll tweak our data slightly and re-upload to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_df = pd.read_csv(f\"./data/{target_train_filename}\")\n",
    "target_test_df = pd.read_csv(f\"./data/{target_test_filename}\")\n",
    "related_df = pd.read_csv(f\"./data/{related_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target timeseries must specify `timestamp`, `item_id`, `demand`, and preferably no other fields.\n",
    "\n",
    "Our canonical data is already really close to this, so we'll just rename the customer_type field to the more Forecast-y item_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_df.rename(columns={ \"customer_type\": \"item_id\" }, inplace=True)\n",
    "target_test_df.rename(columns={ \"customer_type\": \"item_id\" }, inplace=True)\n",
    "target_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related timeseries in this domain:\n",
    "\n",
    "1. Must specify `timestamp` (which we already have)\n",
    "2. Must specify `item_id` (which we don't currently as the weather is not customer_type specific)\n",
    "3. Suggest a number of optional domain fields, but none map very closely to our data set\n",
    "\n",
    "...and all data sets in general:\n",
    "\n",
    "4. Must not any of the documented [reserved field names](https://docs.aws.amazon.com/forecast/latest/dg/reserved-field-names.html) (including `temp`)\n",
    "5. Can consist of fields with types `string`, `integer`, `float`, or `timestamp` as specified in the user [schema](https://docs.aws.amazon.com/forecast/latest/dg/API_SchemaAttribute.html)\n",
    "\n",
    "We'll ignore the lack of support for boolean fields, since loading the data as strings will have equivalent results.\n",
    "\n",
    "Therefore we'll prepare the data by:\n",
    "\n",
    "* Duplicating our related timeseries data for all item_ids (per point 2.)\n",
    "* Renaming the `temp` column to `temperature` (per point 4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate data for each item_id in the target dataframe:\n",
    "related_peritem_dfs = []\n",
    "item_ids = target_train_df[\"item_id\"].unique()\n",
    "for item_id in item_ids:\n",
    "    df = related_df.copy()\n",
    "    df[\"item_id\"] = item_id\n",
    "    related_peritem_dfs.append(df)\n",
    "\n",
    "related_df = pd.concat(related_peritem_dfs).sort_values([\"timestamp\", \"item_id\"]).reset_index(drop=True)\n",
    "\n",
    "# Rename any reserved columns to keep Forecast happy:\n",
    "related_df.rename(columns={ \"temp\": \"temperature\" }, inplace=True)\n",
    "related_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...Now store the data in S3 ready to import to Amazon Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing dataframes to file...\")\n",
    "!mkdir -p ./data/amzforecast\n",
    "target_train_df.to_csv(\n",
    "    f\"./data/amzforecast/{target_train_filename}\",\n",
    "    index=False\n",
    ")\n",
    "target_test_df.to_csv(\n",
    "    f\"./data/amzforecast/{target_test_filename}\",\n",
    "    index=False\n",
    ")\n",
    "related_df.to_csv(\n",
    "    f\"./data/amzforecast/{related_filename}\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Uploading dataframes to S3...\")\n",
    "s3.upload_file(\n",
    "    Filename=f\"./data/amzforecast/{target_train_filename}\",\n",
    "    Bucket=bucket,\n",
    "    Key=f\"{data_prefix}amzforecast/{target_train_filename}\"\n",
    ")\n",
    "print(f\"s3://{bucket}/{data_prefix}amzforecast/{target_train_filename}\")\n",
    "s3.upload_file(\n",
    "    Filename=f\"./data/amzforecast/{target_test_filename}\",\n",
    "    Bucket=bucket,\n",
    "    Key=f\"{data_prefix}amzforecast/{target_test_filename}\"\n",
    ")\n",
    "print(f\"s3://{bucket}/{data_prefix}amzforecast/{target_test_filename}\")\n",
    "s3.upload_file(\n",
    "    Filename=f\"./data/amzforecast/{related_filename}\",\n",
    "    Bucket=bucket,\n",
    "    Key=f\"{data_prefix}amzforecast/{related_filename}\"\n",
    ")\n",
    "print(f\"s3://{bucket}/{data_prefix}amzforecast/{related_filename}\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a Dataset Group\n",
    "\n",
    "Open up the Amazon Forecast console (in the same `region` that we selected earlier!). You might see the landing page below, or a different dashboard if you've used the service before.\n",
    "\n",
    "Click \"Create Dataset Group\" either from the landing page or from the \"Dataset Groups\" tab of the expandable left-side menu.\n",
    "\n",
    "<img src=\"BlogImages/AmazonForecastDashboard.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your dataset group **`bikeshare_dataset_group`** and select the **`Retail`** demand as discussed above.\n",
    "\n",
    "Click Next to continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Target Dataset\n",
    "\n",
    "Next you'll be prompted to create the target data set with a form like the below (or, if not, can choose to create a target dataset from the dashboard)\n",
    "\n",
    "<img src=\"BlogImages/CreateDataset.png\"/>\n",
    "\n",
    "First, let's review our dataframe's structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to:\n",
    "\n",
    "* Give the dataset a name: **`bikeshare_target_dataset`**\n",
    "* Adjust the granularity to **`hourly`**, matching our data\n",
    "* **`Re-order the columns in the data schema`**, to match the dataframe above\n",
    "\n",
    "When you've made the changes, go ahead and click \"Next\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Import target timeseries data\n",
    "\n",
    "Next you'll be prompted to create a *dataset import job* (or, if not, can choose to do so from the dashboard).\n",
    "\n",
    "* Name the import job **`bikeshare_target_import`**\n",
    "* Check the timestamp format matches our dataframe\n",
    "* Select \"Create a new role\", and grant it access to either all buckets or just the one created for this exercise\n",
    "* Provide the **target training** file S3 URL (hint: We printed it out near the end of step 2)\n",
    "\n",
    "<img src=\"BlogImages/ImportTargetTimeseries.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you click \"Start Import\", you'll be taken back to the Forecast dashboard page.\n",
    "\n",
    "Note that:\n",
    "\n",
    "* Dataset imports can take several minutes to complete, because Amazon Forecast spins up resources to handle the task in a scalable way and performs validation of the data set.\n",
    "* You don't need to wait for the target data import to complete to start the related data import (next step)\n",
    "* It's possible to train a \"predictor\" (a forecast model) as soon as the target data is imported, but we can achieve better accuracy by waiting for the related data to be imported as well and using it in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create and import Related Timeseries Dataset\n",
    "\n",
    "Next, select the option to create/import a related dataset.\n",
    "\n",
    "Let's review the structure of our related data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll name the new dataset **`bikeshare_related_dataset`**.\n",
    "\n",
    "Remember to select **`hourly`** frequency!\n",
    "\n",
    "This time, we'll have to make a lot more edits to the dataset schema to capture all of our columns.\n",
    "\n",
    "The API docs give low-level details of what each [SchemaAttribute](https://docs.aws.amazon.com/forecast/latest/dg/API_SchemaAttribute.html) can contain, and the overall [Schema](https://docs.aws.amazon.com/forecast/latest/dg/API_Schema.html) object. For our example, the below should work:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"Attributes\": [\n",
    "        {\n",
    "            \"AttributeName\": \"timestamp\",\n",
    "            \"AttributeType\": \"timestamp\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"season\",\n",
    "            \"AttributeType\": \"float\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"holiday\",\n",
    "            \"AttributeType\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"weekday\",\n",
    "            \"AttributeType\": \"float\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"workingday\",\n",
    "            \"AttributeType\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"weathersit\",\n",
    "            \"AttributeType\": \"float\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"temperature\",\n",
    "            \"AttributeType\": \"float\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"atemp\",\n",
    "            \"AttributeType\": \"float\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"hum\",\n",
    "            \"AttributeType\": \"float\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"windspeed\",\n",
    "            \"AttributeType\": \"float\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"item_id\",\n",
    "            \"AttributeType\": \"string\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is completed, we'll create a dataset import job for it:\n",
    "\n",
    "* Name the import job **`bikeshare_related_import`**\n",
    "* Check the timestamp format matches our dataframe above\n",
    "* The IAM role should be pre-populated for you as we created it for the target dataset import\n",
    "* This time provide the related dataset S3 URL (which we printed out near the end of step 2)\n",
    "\n",
    "Go ahead and click \"Start import\" when you're ready, and you should be returned to the dashboard screen while the data is loaded!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: While the datasets import...\n",
    "\n",
    "With the data volumes in our example, import is usually done within a couple of minutes.\n",
    "\n",
    "In case it's taking longer for you though (especially in group workshops...) - why not make a start on one of the other model fitting notebooks while you wait? e.g. training a model with SageMaker.\n",
    "\n",
    "Note: Although it should usually update live, sometimes you might need to refresh the page on the Amazon Forecast dashboard to see the latest status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train a \"Prophet\" predictor\n",
    "\n",
    "When your dashboard looks like the below, with both target and related data imported, you're ready to start predictor training.\n",
    "\n",
    "For our first predictor, we'll train a model using Facebook's [Prophet](https://facebook.github.io/prophet/) algorithm: A highly successful open source framework based on additive-component regression (as described in the [paper](https://peerj.com/preprints/3190/)).\n",
    "\n",
    "<img src=\"BlogImages/DashboardDatasetsImported.png\"/>\n",
    "\n",
    "First up, we need to review how much of our target series was chopped out from the end of the data-set as test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_samples = len(target_train_df[\"timestamp\"].unique())\n",
    "n_test_samples = len(target_test_df[\"timestamp\"].unique())\n",
    "n_related_samples = len(related_df[\"timestamp\"].unique())\n",
    "\n",
    "print(f\"  {n_train_samples} training samples\")\n",
    "print(f\"+ {n_test_samples} testing samples\")\n",
    "print(f\"= {n_related_samples} total samples (related dataset)\")\n",
    "\n",
    "assert (\n",
    "    n_train_samples + n_test_samples == n_related_samples\n",
    "), \"Mismatch between target train+test timeseries and related timeseries coverage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your predictor, configured as follows:\n",
    "\n",
    "* **Predictor name:** **`bikeshare_prophet_predictor`**\n",
    "* **Forecast horizon:** **336** (2 weeks at 24hrs/day)\n",
    "* **Forecast frequency:** **1 hour** (matching our source data)\n",
    "* **Algorithm selection:** **Manual**\n",
    "* **Algorithm:** **Prophet**\n",
    "* **Country for holidays:** **United States** (where the Capital Bikeshare scheme operates)\n",
    "* **Number of backtest windows:** **4**\n",
    "* **Backtest window offset:** *See below*\n",
    "\n",
    "The [`BackTestWindowOffset`](https://docs.aws.amazon.com/forecast/latest/dg/API_EvaluationParameters.html#forecast-Type-EvaluationParameters-BackTestWindowOffset) parameter sets where the last forecast validation window starts, defaulting equal to `ForecastHorizon` on the assumption that no data has been withheld for external testing.\n",
    "\n",
    "Since we held out data, we'll need to increase this value by the number of samples removed (see code cell above).\n",
    "\n",
    "Assuming your configuration is identical, this will be: 336 + 744 = **1,080**\n",
    "\n",
    "The *NumberOfBacktestWindows* parameter controls how many separate windows Amazon Forecast uses to [evaluate model accuracy](https://docs.aws.amazon.com/forecast/latest/dg/metrics.html): Allowing us to measure performance more robustly than concentrating only on the very end of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Train a \"DeepAR+\" predictor\n",
    "\n",
    "DeepAR+ is perhaps the \"signature\" algorithm of Amazon Forecast: Based on the same neural timeseries modelling [approach](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_how-it-works.html) behind the [SageMaker DeepAR built-in algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html) - but with some proprietary extensions and improvements implemented in Amazon Forecast.\n",
    "\n",
    "We **don't need to wait** for the Prophet predictor to train to kick off another predictor training job: simply go to the \"Predictors\" item in the sidebar menu and click the \"Train new predictor\" button\n",
    "\n",
    "<img src=\"BlogImages/AmazonForecastPredictorCreateInProgress.png\"/>\n",
    "\n",
    "The configuration should be as above, except for:\n",
    "\n",
    "* **Predictor name:** **`bikeshare_deeparplus_predictor`**\n",
    "* **Algorithm:** **Deep_AR_Plus**\n",
    "\n",
    "Once you've kicked off the training, return to the \"Predictors\" screen to track the status of the two training predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Create forecasts (and maybe custom predictors?)\n",
    "\n",
    "If you'd like to fit any other models (e.g. using the AutoML model selection or one of the more baseline architectures like ARIMA), feel free to kick off more training jobs at this point with the same naming conventions and configurations.\n",
    "\n",
    "Our next step is to create a \"forecast\" for each predictor: running the model and extracting predicted confidence intervals.\n",
    "\n",
    "You can kick off forecast creation for each predictor any time it's done training, and Prophet trains relatively quickly so may already be available.\n",
    "\n",
    "Since both predictor fitting and forecast creation can take a while, you can make some progress on the other SageMaker model fitting if you get blocked; and check back every now and then.\n",
    "\n",
    "To create the forecasts, go to Forecasts in the sidebar menu and click the \"Create a Forecast\" button. Configure each forecast as:\n",
    "\n",
    "* **Name:** e.g. **`bikeshare_prophet_forecast`**, **`bikeshare_deeparplus_forecast`**, etc\n",
    "* **Predictor:** selected from the dropdown (if your predictor doesn't appear in the dropdown yet, it probably hasn't finished training)\n",
    "* **Forecast types:** We'll look at **`.10, .50, .90, mean`**\n",
    "\n",
    "<img src=\"BlogImages/CreateAForecast.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As soon as each forecast creation has been kicked off in the console, you'll be able to select that item from the list and should enter the **Forecast ARN** below.\n",
    "\n",
    "**Note that the forecast ARN is different from the predictor ARN!** You can access the list of created forecasts from the \"Forecasts\" tab of the sidebar menu:\n",
    "\n",
    "<img src=\"BlogImages/ProphetForecastDetails.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_arns = {\n",
    "    # Each example should look something like this:\n",
    "    # \"a_nice_name\": \"arn:aws:forecast:[REGION?]:[ACCOUNT?]:forecast/[FORECASTNAME?]\"\n",
    "    \"bikeshare_prophet_forecast\": \"\", # TODO ,\n",
    "    \"bikeshare_deeparplus_forecast\": \"\"# TODO\n",
    "    # More entries if you created other forecasts with different settings too?\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Review model accuracy metrics\n",
    "\n",
    "Because we generate probabilistic forecasts with *confidence intervals*, evaluating the results is not as simple as comparing RMSE scores: There's a **trade-off** between:\n",
    "\n",
    "* accuracy (whether the actual values are within the proposed confidence interval / probability distribution), versus\n",
    "* precision (how narrow the proposed confidence interval is)\n",
    "\n",
    "Predictor metrics calculated on our training set backtesting windows are available directly through the AWS Console:\n",
    "\n",
    "* Go to \"Predictors\" in the sidebar menu\n",
    "* Select a predictor to review and click to view details\n",
    "* Scroll down to the \"Predictor metrics\" section\n",
    "\n",
    "You'll see (example screenshot below) RMSE vs mean and weighted quantile losses at the three 10%, 50%, 90% evaluation points; for each prediction window and summarized by average.\n",
    "\n",
    "**Which predictor seems to perform best from these metrics? Are there any patterns in accuracy over the different prediction windows?**\n",
    "\n",
    "<img src=\"BlogImages/AmazonForecastPredictorMetrics.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Visualise and evaluate forecast quality\n",
    "\n",
    "It's possible (via \"Forecast Lookup\" in the side-bar menu) to view forecast outputs directly in the AWS console: Feel free to try it out!\n",
    "\n",
    "Here though, we'll use the Forecast Query API to programmatically download results and plot in our notebook - which would allow you to construct different visualisations, or custom evaluation metrics.\n",
    "\n",
    "First note that although Forecast understood our source data timestamps for model training, inference has more strict requirements so we'll need to generate start and end timestamps in proper ISO format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test_ts = target_test_df[\"timestamp\"].iloc[0]\n",
    "\n",
    "# Remember we predict to 2 weeks horizon\n",
    "# [Python 3.6 doesn't have fromisoformat()]\n",
    "test_end_dt = datetime(\n",
    "    int(first_test_ts[0:4]),\n",
    "    int(first_test_ts[5:7]),\n",
    "    int(first_test_ts[8:10]),\n",
    "    int(first_test_ts[11:13]),\n",
    "    int(first_test_ts[14:16]),\n",
    "    int(first_test_ts[17:])\n",
    ") + timedelta(days=14, hours=-1)\n",
    "\n",
    "# Forecast wants a slightly different timestamp format to the dataset:\n",
    "fcst_start_date = first_test_ts.replace(\" \", \"T\")\n",
    "fcst_end_date = test_end_dt.isoformat()\n",
    "print(f\"Forecasting\\nFrom: {fcst_start_date}\\nTo: {fcst_end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use the `forecast_arns` dictionary you filled out earlier as a basis to download predictions for each of the created forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = {\n",
    "    predictor_name: {\n",
    "        \"forecast_arn\": forecast_arn,\n",
    "        \"forecasts\": {\n",
    "            item_id: forecast_query.query_forecast(\n",
    "                ForecastArn=forecast_arn,\n",
    "                StartDate=fcst_start_date,\n",
    "                EndDate=fcst_end_date,\n",
    "                Filters={ \"item_id\": item_id }\n",
    "            )\n",
    "        for item_id in item_ids }\n",
    "    }\n",
    "for (predictor_name, forecast_arn) in forecast_arns.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Amazon Forecast and various SageMaker models will produce outputs in different formats, we'll **standardize the results** into a local CSV file to help with cross-system comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_results_df = pd.DataFrame()\n",
    "for predictor_name, predictor_data in forecasts.items():\n",
    "    for item_id, forecast_data in predictor_data[\"forecasts\"].items():\n",
    "        predictions = forecast_data[\"Forecast\"][\"Predictions\"]\n",
    "        pred_mean_df = pd.DataFrame(predictions[\"mean\"])\n",
    "        pred_timestamps = pd.to_datetime(pred_mean_df[\"Timestamp\"].apply(lambda s: s.replace(\"T\", \" \")))\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        df[\"timestamp\"] = pred_timestamps\n",
    "        df[\"model\"] = f\"amzforecast-{predictor_name}\"\n",
    "        df[\"customer_type\"] = item_id\n",
    "        df[\"mean\"] = pred_mean_df[\"Value\"]\n",
    "        df[\"p10\"] = pd.DataFrame(predictions[\"p10\"])[\"Value\"]\n",
    "        df[\"p50\"] = pd.DataFrame(predictions[\"p50\"])[\"Value\"]\n",
    "        df[\"p90\"] = pd.DataFrame(predictions[\"p90\"])[\"Value\"]\n",
    "        \n",
    "        clean_results_df = clean_results_df.append(df)\n",
    "\n",
    "!mkdir -p results/amzforecast\n",
    "clean_results_df.to_csv(\n",
    "    f\"./results/amzforecast/results_clean.csv\",\n",
    "    index=False\n",
    ")\n",
    "print(\"Clean results saved to ./results/amzforecast/results_clean.csv\")\n",
    "clean_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally, we use this standardized format to plot results:\n",
    "\n",
    "(Using our handy plotting function in the util folder, to avoid cluttering up this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, prepare the actual data (training + test) for easy plotting:\n",
    "first_plot_dt = test_end_dt - timedelta(days=21)\n",
    "actuals_df = target_train_df.append(target_test_df)\n",
    "actuals_df[\"timestamp\"] = pd.to_datetime(actuals_df[\"timestamp\"])\n",
    "actuals_plot_df = actuals_df[\n",
    "    (actuals_df[\"timestamp\"] >= first_plot_dt)\n",
    "    & (actuals_df[\"timestamp\"] <= test_end_dt)\n",
    "]\n",
    "actuals_plot_df.rename(columns={ \"item_id\": \"customer_type\"}, inplace=True)\n",
    "\n",
    "util.plot_fcst_results(actuals_plot_df, clean_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and there you have it! Statistical timeseries forecasts created with the AWS console and downloaded/processed in code: No deep data science knowledge required, but with ability to play around with hyperparameters and model architectures if we wanted to dive deeper.\n",
    "\n",
    "**Did the graphs visually agree with your assessment of which models looked best from the console metrics?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension exercises and exploring further\n",
    "\n",
    "Given the formulae listed on the [Amazon Forecast metrics docs](https://docs.aws.amazon.com/forecast/latest/dg/metrics.html) and the example plotting code above, could you calculate the RMSE and weighted quantile loss scores for this prediction window? How do they compare to the scores Amazon Forecast calculated in training?\n",
    "\n",
    "Might we get better performance with a different dataset group **domain**? Some domains might have different column name and type requirements, so might need to do some more data manipulation!\n",
    "\n",
    "Amazon Forecast has some built-in time featurization capability, which is why it's important to provide correct, absolute date/timestamps. Does removing the `workingday` related timeseries feature have much impact on prediction quality? How about `holiday`? What if we offset the timestamps of the whole data-set by one calendar day?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks for joining in! (Clean-up time)\n",
    "\n",
    "[Amazon Forecast pricing](https://aws.amazon.com/forecast/pricing/) is by:\n",
    "\n",
    "* Generated forecasts\n",
    "* Data storage, and\n",
    "* Training hours\n",
    "\n",
    "...So there are no real-time endpoint compute resources to worry about deleting like some services: but it might still be worth cleaning up if the data storage cost is significant for you at these sizes.\n",
    "\n",
    "You can delete all resources (forecasts, forecast exports if you triggered any, predictors, import jobs, datasets, and dataset groups) through the Amazon Forecast console. Consider also clearing out the S3 bucket, and stopping this notebook instance if running on SageMaker!\n",
    "\n",
    "We hope you've enjoyed this section and any others you're still working on. If you have any feedback for this workshop, please do get in touch via the GitHub or workshop facilitators!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
